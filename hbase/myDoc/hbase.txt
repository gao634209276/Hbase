Apache HBase 是Hadoop database的简称，hbase 是一个分布式，可扩展的，面向大数据存储的数据库。
     HBase 基本概念
     1、region 
          region 是部分数据，所以是所有数据的一个自己，但region包括完整的行，所以region 是行为单位 表的一个子集。
          每个region 有三个主要要素:

它所属于哪张表
它所包含的的第一行(第一个region 没有首行)
他所包含的最后一行(末一个region 没有末行)
          当表初写数据时，此时表只有一个region ,当随着数据的增多，region 开始变大，等到它达到限定的阀值大小时，变化把region 分裂为两个大小基本相同的region,
    而这个阀值就是storefile 的设定大小(参数:hbase.hregion.max.filesize 新版本默认10G) ,在第一次分裂region之前，所有加载的数据都放在原始区域的那台服务器上，随着表的变大
    region 的个数也会相应的增加，而region 是Hbase集群分布数据的最小单位。
          (但region 也是由block组成，具体这个block和hdfs block什么样的关系后面再说，region是属于单一的regionserver，除非这个regionserver 宕机，或者其它方式挂掉，再或者执行balance时，才可能会将这部分region的信息转移到其它机器上。)
          * 这也就是 为什么region比较少的时候，导致region分配不均，总是分派到少数的节点上，读写并发效果不显著，这就是hbase 读写效率比较低的原因。
     2、加锁
          HBase的锁 是行锁，无论对行进行访问的事物有多少列，那对此行的更新都会是原子操作，要么成功，要么失败，不会存在部分成功的情况。这就说明，如果只更新一个行1000个列
     中的一个列，那也会对正行加锁。
     3、Hbase元数据表
          HBase内部维护着两个元数据表，分别是-ROOT- 和 .META. 表 他们分别维护者当前集群所有region 的列表、状态和位置。-ROOT-表包含.META.表的region 列表，因为.META.
     表可能会因为超过region的大小而进行分裂，所以-ROOT-才会保存.META.表的region索引，-ROOT-表是不会分裂的。而.META. 表中则包含所有用户region（user-space region）
     的列表。表中的项使用region 名作为键。region名由所属的表名、region的起始行、创建的时间 以及对其整体进行MD5 hash值。
          比如:
                  award_week_2013,201311:170100626,1371697714559.f7f37b98c01f68b7b5cc6c1c3734a666
                 |--表名-------------|-----起始行---------|--创建时间戳---|----整体进行MD5 hash 值------------|
          由此我们联想到 表scan 的过程中如果加了 STARTROW 和 ENDROW 的属性后，查找是很迅速的，就是因为根据给定rowkey从.META.表中 找到所在的region,然后再从
     region去查找。
          这个表的值什么时候会变化？
          当region 进行split、disable、enable、drop或者 balance 导致region重新分配 或者由于regionserver 挂掉而导致重新分配region时，.META.表的数据会进行及时的更新，
     这样才能保证根据meta访问到的表是存在的。
    

      
     4、访问流程

客户端client 首先连接到ZooKeeper 这是就要先查找-ROOT-的位置。
然后client通过-ROOT- 获取所请求行所在范围 所属的.META.region的位置。
client接着查找.META.region来获取user-space region 所在的节点和位置。
接着client 就可以直接和管理者那个region的RegionServer 进行交互。
        注：
             每个行操作可能要访问三次远程节点，为了节省这些代价，client会缓存他们遍历-ROOT-和.META. 的位置以及user-space region的开始行和结束行，这样每次访问就不
     会再从表中去查询了，但如果变动了怎么办？却是存在这个问题，这样的话client 会出现错误，那此时region毫无疑问是移动了，这时，client 会再次从.META.查找region 的
     新位置并再次将其放入到缓存中去，周而复始。同样道理如果.META.的region移动了，client 也才会去-ROOT-表查询.META.region的新位置。
          不过由于hbase 设计的问题，所以在MapReduce过程中如果用到hbase时，访问缓存中的region就会出现错误，出现错误后，缓存更新，task再次尝试就能正确通过
          下面是我们常遇到的bug：
          2013-09-24 01:26:15,487 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
          Closing scanner for    tmp_toplist_gold_total_1001,,1379956828778.4a8e5f51eafc48aed247913c715a8cc1.
           org.apache.hadoop.hbase.NotServingRegionException: Region is not online: tmp_toplist_gold_total_1001,,1379956828778.4a8e5f51eafc48aed247913c715a8cc1.
          基于这种情况会时常发生， 建议不要让task 尝试的次数改为1，这样会导致很多job fail
          这两个参数分别是：

 mapred.map.max.attempts map 任务最大尝试次数 默认是4
 mapred.reduce.max.attempts reduce 任务最大尝试次数 默认是4
       5、Zookeeper的作用
            Zookeeper简单说就是协调和服务于分布式应用程序的服务。
            Zookeeper Quorum 中除了存储-ROOT-表的地址和Hmaster 的地址，HRegionServer 也以Ephemeral的方式注册到Zookeeper中，这样Hmaster 就可以随时感知到各个
      RegionServer的健康状况，还有就是Zookeeper通过Election的方式 避免了Hmaster的单点问题。

保证任何时候，集群中只有一个master
存贮所有Region的寻址入口。
实时监控RegionServer的状态，将Region server的上线和下线信息实时通知给Master
存储Hbase的schema,包括有哪些table，每个table有哪些column family  

          
     6、Hmaster
            上面说了，Zookeeper避免了HMaster的单点问题，一个Hbase集群可以启动多个HMaster，而Zookeeper通过Election的方式保证集群中只有一个HMaster处于live的状态
       其它都处于休眠的状态，如果HMaster出现问题，则Zookeeper 则唤醒其它休眠的HMaster。
               HMaster 在功能上主要负责哪些工作呢？
               1、管理用户对Table的增、删、改、查操作
               2、管理RegionServer的负载均衡、调整Region的分布
               3、在Region Split后，将新Region分布到不同的RegionServer。
               4、在RegionServer宕机后，那该RegionServer上所管理的Region 由HMaster进行重新分配。
          总结HMaster 的主要任务：1、HTable DDL 操作 2、Region 分配工作。 其余的基本上都是client 和RegionServer打交道来完成的。

      7、HRegionServer
            HRegionServer 主要负责相应用户的I/O请求，进而跟HDFS交互，从HDFS中读写数据，虽然每个进程都很重要，但个人认为HRegionServer是HBase中最核心的进程。
            下面对HRegionServer的内部结构做一个简单描述:
            HRegionServer 内部管理了一系列的HRegion对象，HRegion和Region是一回事吗？其实HRegion对应了Table中的一个Region，HRegion是对其进行的封装。每个HRegion
     中由多个HStore组成。
            HStore则对应Table中的Column Family，不论此Column Family 内部有多少数据，都会创建一个新的HStore,因此将相同属性的数据放进相同的Column Family 很有
     必要，避免一次访问，访问多个HStore，性能低下。而HStore 则是HBase的核心的存储单元了，而HStore 由两个部分组成，一时MemStore,再就是StoreFile 
            MemStore 是Sorted Memory Buffer ,client 写入的数据先写入MemStore,当达到MemStore的阀值时，将其Flush 成为一个StoreFile(HFile),StoreFile 则是存储在硬盘上的
           文件，具体这个阀值时多少？
            hbase.hregion.memstore.flush.size  这个参数表示每个MemStore的大小，当然系统默认是134217728 bytes 也就是128M，这个参数需考虑每个RS负担的Region个数。
            这个参数的作用是当单个Region内所有的memstore大小总和超过指定值时，flush该region的所有memstore。RegionServer的flush是通过将请求添加一个队列，模拟生产
     消费模式来异步处理的。那这里就有一个问题，当队列来不及消费，产生大量积压请求时，可能会导致内存陡增，最坏的情况是触发OOM。
            上面说到，当该Region下所有的MemStore 之和超过指定值时，就触发flush，而前面又说了在一个Region下 每个Column Family 一个HStore ,那多个Column Family 这样
     问题出来了，如果一个HStore数据量大，而另外一个HStore 仅有几条数据，会同时 flush吗?  对，这就说明了一个问题，在Hbase表设计的时候尽量设置单一ColumnFamily的
     表，否则Hbase不能很好的处理上面类似的问题。
             除了上面的参数还有两个参数
             hbase.regionserver.global.memstore.upperLimit 默认 0.4 也就是40%
             为了防止MemStore占用总内存过大，当RegionServer所有Region达到总heap内存的40%，Hbase会Block所有的更新，来flush所有的MemStore,并释
             放MemStore占用的内存
             hbase.regionserver.global.memstore.lowerLimit 默认是 0.35 也就是 35%
             这个参数表示，当该RegionServer 下所有的MemStore达到 总Heap 内存的35%时，触发flush个别占用内存大的MemStore,这是会做block，写更新还
          是会收影响。

     8、HBase数据存储
          1、HBase中所有的数据都是存放在Hadoop HDFS文件系统上，而这部分文件包括两种文件类型：
               一是HFile Hadoop的二进制文件，实际上是StoreFile对HFile 做了一个轻量级包装，所以StoreFile 的底层就是Hfile。
               二是HLog File 也就是HBase的WAL (Write Ahead Log)，实际上在hadoop内部以Sequence File 的形式存在。什么是Sequence File 会在后面的Hadop章节中做介绍,现在
     了解它是一个由二进制序列化过的key/value的字节流组成的文本存储文件。
               下面是HFile 的存储格式，也是官方的一个图。
                
               再把第二张图贴出来：
                
 
               结合上面两张图看，更加直观，第一张图是HFile 文件的格式，下面图是其中Data Block 中KeyValue的 详细结构，如果第一张图相当于分子的话，那第二张就是原子，最小的不可再分的。
               看第一张:HFile文件是不定长的，订场的只有其中两块 FileInfo 和 Trailer 分别存储文件的Meta信息，比如AVG_KEY_LEN,LAST_KEY,COMPARATOR,MAX_SEQ_ID_KEY等信息,Data Index 和 Meta Index 分别记载了每个Data块和Meta块的起始点。Data Block 是 HBase I/O的基本单元，这看到了 Region 最后也是到了Block，不过这个Block是可以手动设置的。
               比如:create 'newtable',{NAME=>'info',BLOCKSIZE=>'131072'},我就是将Family info 的BlockSize 设置为132072  就是是128M 默认是65536 也就是64M刚好和hadoop的hdfs   block 也就是dfs.block.size 默认也是64M 是一样的?对吗?错误，Hbase 列族Data Block size 是 65536字节 也就是64k 是hdfs block size的 1/1024,这地方和Hdfs是一个区别，采用这么细粒度，目的在块操作 时更有效的加载和缓存数据，它不依赖于HDFS 块的尺寸设计，而仅仅属于hbase内部的一个属性，而HDFS把块设计成64M是方便MapReduce时使用.
               下面再把Data 打开看看它内部有些什么东西，Magic 和繁多的KeyValue.
               Magic内容就是一些随机数字，目的是防止数据损坏，而KeyValue 再次放大 看第二张图,KeyValue的结构图:
                    开始是两个固定长度的数值，分别表示Key的长度和Value的长度。紧接着是Key，开始是固定长度的数值，表示RowKey的长度，紧接着是RowKey，然后是固定长度的数值，表示
 Family的长度，然后是Family，接着是Qualifier，然后是两个固定长度的数值，表示Time Stamp和Key Type（Put/Delete）。Value部分没有这么复杂的结构，就是纯粹的二进制数据。
                    HLog File 机构不做详细的说明了，是SequenceFile 文件，仅做一下HLogFile是如果工作的介绍一下:
                    Client 想Hbase 写数据的时候，会同时写MemStore 和 HLog ,当间隔一定的时间，MemStore 永久存储到硬盘中了，也就是由MemStore flush成storeFile 了，那这部分Hlog就会删除
               但是，当MemStore还没写到硬盘中时，RegionServer 突然挂了怎么办?那这时HMaster 该粉墨登场了，它会将Hlog 根据分配到不同的region中，并将挂了的RegionServer 下的Region重
               新分配到新的RegionServer,当RegionServer Load Region的时候，发现有为处理的HLog，那就通过Replay log的方式写入到MemStore 中，完成数据恢复。
