HBase 架构详解

HBase架构
---------------------------------------------------
HBase 组件
	Client-->Zookeeper-->HMaster
	Hbase[HRegionServer[HLog,HRegion(Store:MemStore,StoreFile(HFile))],HRegionServer]
	DFSClient-->HDFS:DataNode
客户端Client
	整个HBase集群的入口
	使用HBase RPC机制与HMaster和HRegionserver通信
	与HMaster通信进行管理类的操作
	与HRegionserver通信进行读写类操作
	包含访问HBase的接口，并维护cache来加快对HBase的访问，与HRegionserver交互
程序协调服务Zookeeper
	保证任何时候，集群中只有一个Master(HA)
	存贮所有Region的寻址入口
	实时监控Region server的上线和下线信息。并实时通知给Master
	存储HBase的schema和table元数据
HBase主节点Master
	管理用户对Table的增删改查操作
	管理HRegionServer的负载均衡，调整Region分布
	在Region Split后，负责新Region的分配
	在HRegionServer停机后，负责失效HRegionServer上的Region迁移
	HMaster失效仅会导致所有元数据无法被修改，表的数据读写还是可以正常进行
HRegionServer节点
	维护Hregion并往HDFS中写数据
	当表的大小超过设置值得时候，Split HRegion
	在HRegionServer停机后，负责失效HRegionServer上的Region迁移

HBase与Zookeeper
	HBase元数据存储在Zookeeper中
	默认情况下，HBase 管理ZooKeeper 实例，比如，启动或者停止ZooKeeper
	Zookeeper解决HBase单节点故障问题
	HMaster与HRegionserver启动时会向Zookeeper注册
HBase Region 定位
	寻找RegionServer过程详解
	ZooKeeper（读取Zookeeper找到-ROOT-表的位置）
	-ROOT-(-ROOT-表包含.META.表所在的region列表，该表只会有一个Region;Zookeeper中记录了-ROOT-表的location)
	.META.(.META.表包含所有的用户空间region列表，以及RegionServer的服务器地址)
	注:目前版本乜有-ROOT-表,现在定位是直接通过META表获取位置信息
	用户表
	Client第一次操作后，会将-ROOT-和.META.缓存到本地，不需要再访问zookeeper
HBase容错性
	Master容错：Zookeeper重新选择一个新的Master
		无Master过程中，数据读取仍照常进行；
		无master过程中，region切分、负载均衡等无法进行
	RegionServer容错：定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳
		Master将该RegionServer上的Region重新分配到其他RegionServer上
		失效服务器上“预写”日志由主服务器进行分割并派送给新的RegionServer
	Zookeeper容错
		Zookeeper高可靠的服务，不存在单点故障


---------------------------------------------------
HBase数据存储
	HMaster 	 分配region到各个HRegionServer中一个共享的Hlog
	HRegionServer 	HRegion Server将每个table的CF存储为Store
	HStore（MemStore和StoreFile） 	Store为表的存储对象，包含多个StoreFile
	StoreFile 	StoreFile为Store对象的操作单位，包含多个HFile
	HFile 	HFile为实际存储数据的对象，包含多个Block
	Block 	Block 64k，Hbase存储的最小单位
	HDFS 	Block存储在HDFS上，每个Hadoop-block是64M
	KeyValue 存储结构
	HLog文件结构
HBase中的所有数据文件都存储在Hadoop HDFS文件系统上，格式主要有两种：
	HFile：HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，
		实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile.
		HFile为实际存储数据的对象，包含多个Block
	HLog File：HBase中WAL（Write Ahead Log）的存储格式，
		物理上是Hadoop的Sequence File带项目符号的内容

---------------------------------------------------
HBase数据存储
Get取数据过程
	1.load and cached
		a.（只有第一次访问此rowkey）访问（-Root-）获取zookeeper的host
		访问（-META-）获得regionServer，（-META-包含每个rowkey所在region srver）
		b.有缓存时使用StoreFile读取数据
Put存储数据
	1.WAL
		包含Sequence File，HLogKey实例
		数据为Sequential number（可让数据Put有序化）和实际数据
	2.MemStore
		当MemStore满（由hbase.hregion.menstore.flush.size配置，默认64M）
		会起个线程，将数据转移到disk上（hdfs）
	3.HFile hdfs

总体过程
	Client:put/delete/incr-->数据(KV形式)-->(Zookeeper-->Meta表-->RegionServer)
	-->HRegionServer
		-->Log Flusher:sync()-->HLog//线程同步
		-->Log Roller:rollWriter()-->HLog
	-->HRegion
		-->MemStore-->StoreFile-->HFile//Mem达到一定大小后写入磁盘StoreFile,文件达到一定个数后合并HFile
HRegionServer
	HRegionServer管理一些列HRegion对象
	每个HRegion对应Table中一个Region，HRegion由多个HStore组成
	每个HStore对应Table中一个Column Family的存储
	Column Family就是一个集中的存储单元，故将具有相同IO特性的Column放在一个Column Family会更高效
HStore
	用户写入数据的流程：
	StoreFile1（64MB）,StoreFile2（64MB）,StoreFile3（64MB）,StoreFile4（64MB）
	--(Compact)-->StoreFile5（256MB）
	--(Split)-->StoreFile5A（128MB）,StoreFile5B（128MB）
	-->StoreFile6（128MB）,StoreFile7（128MB）
	文字描述过程:
	Client写入 -> 存入MemStore，一直到MemStore满 -> Flush成一个StoreFile，直至增长到一定阈值
	-> 出发Compact合并操作 -> 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除
	-> 当StoreFiles Compact后，逐步形成越来越大的StoreFile
	-> 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，
	新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上

	HBase只是增加数据，有所得更新和删除操作，都是在Compact阶段做的，
	所以，用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能

StoreFile文件结构
	StoreFile以HFile格式保存在HDFS上
	Data Block 段–保存表中的数据，这部分可以被压缩
	Meta Block 段 (可选的)–保存用户自定义的kv对，可以被压缩
	File Info 段–Hfile的元信息，不压缩，用户也可以在这一部分添加自己的元信息
	Data Block Index 段–Data Block的索引。每条索引的key是被索引的block的第一条记录的key
	Meta Block Index段 (可选的)–Meta Block的索引
	Trailer–这一段是定长的，保存的是每一段的偏移量
	压缩
		HFile的Data Block，Meta Block通常采用压缩方式存储
			好处：压缩之后可以大大减少网络IO和磁盘IO
			坏处：需要花费cpu进行压缩和解压缩
		HFile支持的压缩格式：Gzip，Lzo，Snappy。。。。
KeyValue存储
	Data(Magic,KeyValue,KeyValue...),Data,Data...Meta(Optional),Meta...File Info,Data Index,Meta Index,Trailer
	HFile里面的每个KeyValue对就是一个简单的byte数组
	KeyLength和ValueLength：两个固定的长度，分别代表Key和Value的长度
	Key部分：Row Length是固定长度的数值，表示RowKey的长度，Row 就是RowKey
	Column Family Length是固定长度的数值，表示Family的长度,
		接着就是Column Family，再接着是Qualifier，然后是两个固定长度的数值，表示Time Stamp和Key Type（Put/Delete）
	Value部分没有这么复杂的结构，就是纯粹的二进制数据
HLog文件结构
	结构顺序如下:
	Key Length(4B),Value Length(4B),Key[Row Length(2B),Row...,ColumnFamily,ColumnQualifier,TimeStamp(8B),KeyType(1B)],Value
	1.HLog文件就是一个普通的Hadoop Sequence File，
	Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，
	除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是“写入时间”，
	sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。
	2.HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue
---------------------------------------------------
HBase内部表

HBase 内部表
	-ROOT- 表
		存储.meta.表信息，-root-表中仅有一行数据,新版本root表被弃用,取代的是zookeeper表
		Zookeeper中存储了-ROOT-表的位置信息
	.META. 表
		主要存储HRegin的列表和HReginServer 的服务器地址
	Namespace表
		存储命名空间
hbck 修复错误表
shell练习:
	list_namespace_tables hbase
	scan 'hbase:namespace'
	create_namespace 'ns1'
	scan 'hbase:meta'
	meta表存储每个region的信息,
		column=info:regioninfo描述整个region信息,
			其中ENCODED => e54db7bdd60a6e435332f41fed146340表示在目录中表的目录名称
		column=info:seqnumDuringOpen存储的是序列化
		column=info:server存储regionserver地址和端口
		column=info:serverstartcode,存储编码信息
	在meta表中删除t2的元数据信息
	deleteall 'hbase:meta',"t2,,1479635890764.4da362814bd89efc1aff21cde43a8dc6.'
	不退出shell扔能scan 't2'查看,退出shell,重新打开后显示不存在此表
	从hdfs中能看到文件依然存储,使用hbase运维工具hbck:
	hbase hbck -fix

---------------------------------------------------
HBase管理命令

Flush
	create 't3','info'
	hadoop fs -ls /user/hbase/data/default/t3/89b90d6ce858ba3f7a4627c070aa03d1/info
	put 't3','rk0001','info:name','lisi'
	插入一条记录后,在hdfs上没看到文件,使用flush操作
	flush 't3'
	flush后,看到在hdfs中形成了文件,
Compact
	当进行三次flush产生三个文件后,hbase进行自动的Compact合并操作
	put 't3','rk0002','info:name','lisi2'
	flush 't3'
	put 't3','rk0003','info:name','lisi3'
	flush 't3'
	可以手动进行Compact,在hbase tool下的操作:
	compact 't3'
Region
	split 't3','rk0002'
	hadoop:16020查看,产生两个region
	关闭region
	通过meta表或者web ui查看region的名称,如下
	close_region 't3,,1479637399309.ec1bbfffa03c01ef1ad68f07b7e58e1e.'
	关闭后,scan 't3'扫描该表报错不在线,需要重新启动region
	assign 't3,,1479637399309.ec1bbfffa03c01ef1ad68f07b7e58e1e.'
















